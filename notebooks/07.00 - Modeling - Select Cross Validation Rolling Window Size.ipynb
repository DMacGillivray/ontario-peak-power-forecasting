{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07.00 - Modeling - Prophet Model & Select Cross Validation Rolling Window Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " + We have data for each summer from 1994 to 2018\n",
    " + We initially decided that the minimum size of the hold out test data is 5 years from 2014 to 2018\n",
    " + We want to select a rolling window that extracts as much value as possible fom the data, but that leaves as much data as possible as hold-out data\n",
    " + Prophet seems to have good out of the box performance, and runs faster than statsmodels ARIMA\n",
    " + We beleive that there are some underlying structural changes that have changed cause and effect relationships between features and power demand between 1994 and 2018\n",
    " + The feature data is limited to weather. We do not have data for items such as air conditioner penetration, conserrvation growth (eg LEDs), population growth, housing stock types.\n",
    " + Therefore, I am going to make the assertion that next year's power demand pattern more closely resembles this year's pattern rather than last year's\n",
    " + We could introduce some sort of decay scheme where more recent data is weighted more heavily than older data. But this does not help us maximize the size of the held-out test data\n",
    " \n",
    "#### One approach could be:\n",
    " + We will use only the power data, and run a series of incrementally increasing cross validation windows across the data between 1994 and 2013\n",
    " + Based on the results we will select a window for the rolling time series cross validation to use in the rest of the modeling process. We will select the window by running prophet on an incremetally increasing sequence of rolling windows, and look for either a best size, or a size beyond which we get diminishing returns.\n",
    " + I realize that this is breaking some rules.If the window proves to be 3 years then to get 10 cross folds, my hold out data will be from 2008 to 2018. But, I will have already \"touched\" some of this data when I determined the size of the rolling window. \n",
    "\n",
    "#### Another approach could be:\n",
    " + Make a judgement as to a reasonable time period\n",
    " \n",
    "#### Making a judgement:\n",
    " + If I had to draw a chart of next year's demand by reviewing a chart of the last 100 years of data, I would draw a chart that looked exactly the same as last year + or - any obvious trend.\n",
    " + We are making a prediction for a single year ahead, using our cross validation scheme i.e the validation set comprises one year. If we only choose a single year of test data, then our model will miss out on trends, and will be working on a 50/50 train test split. Therefore, our training period should be greater than 1 year.\n",
    " + Two years of training data is not enough because a degree of randomness is introduced by the weather. ie. if we have a hot summer followed by a cold summer, this could be seen as a trend, but it is really randomness. Therefore, our training period should be greater than 2 years.\n",
    " + Twenty years seems too long because diverse undelying structural changes in the demand patterns mean that year 1 is not really the \"same\" as year 20\n",
    " + At this point, I have delayed making this decision long enough, and I am going to (semi-)arbitrarily select a training period of 5 years. This gives a train/ validation split of 83/17% which seems reasonable. My opinion is that this period is long enough to capture trends, and short enough to give a reasonably close representation of the validation data\n",
    " + I want to keep 10 cross folds in order to capture the uncertainty in the model\n",
    " + Therefore my data split will look like this:\n",
    "     + Training Data - 1994 to 2009 with a 10 fold rolling tiome series cross validation\n",
    "     + Test Data - 2010 to 2018 - 9 years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import pickle\n",
    "import joblib\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "\n",
    "# Imports\n",
    "sys.path.append(\"..\")\n",
    "from src.utils.utils import (AnnualTimeSeriesSplit,\n",
    "                             RollingAnnualTimeSeriesSplit,\n",
    "                             bound_precision,\n",
    "                             run_cross_val,\n",
    "                             run_data_split_cross_val,\n",
    "                             save_run_results)\n",
    "from src.features.features import CyclicalToCycle\n",
    "from src.models.models import SK_SARIMAX, SK_Prophet, SetTempAsPower, SK_Prophet_1\n",
    "from src.visualization.visualize import (plot_prediction,\n",
    "                                         plot_joint_plot,\n",
    "                                         residual_plots,\n",
    "                                         print_residual_stats,\n",
    "                                         resids_vs_preds_plot)\n",
    "#b # Packages\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skoot.feature_selection import FeatureFilter\n",
    "from skoot.preprocessing import SelectiveRobustScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import norm\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import statsmodels.api as sm\n",
    "from fbprophet import Prophet\n",
    "\n",
    "# Display\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "figsize=(15,7)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "# Data\n",
    "PROJECT_DIR = pathlib.Path.cwd().parent.resolve()\n",
    "CLEAN_DATA_DIR = PROJECT_DIR / 'data' / '05-clean'\n",
    "MODELS_DIR = PROJECT_DIR / 'data' / 'models'\n",
    "RESULTS_PATH = PROJECT_DIR / 'data' /'results' / 'results.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Daily Data & Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(CLEAN_DATA_DIR / 'clean-features.csv', parse_dates=True, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmdxx_min</th>\n",
       "      <th>hmdxx_max</th>\n",
       "      <th>hmdxx_median-1</th>\n",
       "      <th>hmdxx_max_hour</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>dew_point_temp_max</th>\n",
       "      <th>sun_rise</th>\n",
       "      <th>sun_set</th>\n",
       "      <th>visibility_mean</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>day_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1994-05-24</td>\n",
       "      <td>8.998045</td>\n",
       "      <td>19.818202</td>\n",
       "      <td>19.655075</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>13.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.975000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1994-05-25</td>\n",
       "      <td>11.406291</td>\n",
       "      <td>20.665711</td>\n",
       "      <td>17.205396</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>18.2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.358333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1994-05-26</td>\n",
       "      <td>2.563201</td>\n",
       "      <td>15.259916</td>\n",
       "      <td>17.722172</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.650000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1994-05-27</td>\n",
       "      <td>-0.012865</td>\n",
       "      <td>12.970553</td>\n",
       "      <td>6.567827</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1994-05-30</td>\n",
       "      <td>13.632519</td>\n",
       "      <td>30.133976</td>\n",
       "      <td>18.724332</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>27.2</td>\n",
       "      <td>13.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.270833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hmdxx_min  hmdxx_max  hmdxx_median-1  hmdxx_max_hour  temp_min  temp_max  dew_point_temp_max  sun_rise  sun_set  visibility_mean  day_of_week  week_of_year  day_type\n",
       "1994-05-24   8.998045  19.818202       19.655075            15.0       9.0      19.6                13.4       6.0     21.0        24.975000          1.0          21.0         2\n",
       "1994-05-25  11.406291  20.665711       17.205396            18.0      10.4      18.2                14.0       6.0     21.0         9.358333          2.0          21.0         0\n",
       "1994-05-26   2.563201  15.259916       17.722172             2.0       3.9      13.0                12.3       6.0     21.0         9.650000          3.0          21.0         0\n",
       "1994-05-27  -0.012865  12.970553        6.567827            17.0       2.0      14.8                 2.3       6.0     21.0        34.500000          4.0          21.0         0\n",
       "1994-05-30  13.632519  30.133976       18.724332            14.0      13.1      27.2                13.6       6.0     21.0        22.270833          0.0          22.0         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.copy(deep=True)\n",
    "X = X.loc['1994': '2009']\n",
    "y = X.pop('daily_peak')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2009-09-28    17197.0\n",
       "2009-09-29    16969.0\n",
       "2009-09-30    17026.0\n",
       "2009-10-01    17462.0\n",
       "2009-10-02    17147.0\n",
       "Name: daily_peak, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prophet Model \n",
    "\n",
    "Run using just the y data - the daily peak demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 4 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': {'mae': [861.9526886500258,\n",
       "   848.7503649387098,\n",
       "   951.9640884002106,\n",
       "   1097.9631256223759,\n",
       "   1046.3089180328611,\n",
       "   1039.6653570615367,\n",
       "   1120.9551950298394,\n",
       "   1150.2820915475443,\n",
       "   1153.026969775874,\n",
       "   1158.48089195951],\n",
       "  'bound_precision': [0.0, 0.0, 0.0, 0.2, 0.2, 0.4, 0.2, 0.0, 0.0, 0.0]},\n",
       " 'test': {'mae': [1123.5511024344235,\n",
       "   1314.1803916051847,\n",
       "   1524.0323306039452,\n",
       "   2071.5448825390963,\n",
       "   1494.9661977544395,\n",
       "   2266.413731752333,\n",
       "   3216.962074235825,\n",
       "   2046.537695763631,\n",
       "   1745.254663302055,\n",
       "   1608.148548303073],\n",
       "  'bound_precision': [0.0, 0.0, 0.2, 0.0, 0.2, 0.2, 0.4, 0.0, 0.0, 0.0]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_splits=10\n",
    "\n",
    "prophet_model = SK_Prophet(pred_periods=96)\n",
    "                           \n",
    "ratscv = RollingAnnualTimeSeriesSplit(n_splits=n_splits, goback_years=5)\n",
    "\n",
    "steps = [('prophet', prophet_model)]\n",
    "pipeline = Pipeline(steps)\n",
    "d = run_cross_val(X, y, ratscv, pipeline, scoring=['mae', 'bound_precision'])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1841.1591618294005\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the results on the validation data\n",
    "print(np.mean(d['test']['mae']))\n",
    "print(np.mean(d['test']['bound_precision']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ana_py37tf]",
   "language": "python",
   "name": "conda-env-ana_py37tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

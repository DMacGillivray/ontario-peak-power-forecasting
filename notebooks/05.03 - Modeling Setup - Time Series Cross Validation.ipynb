{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05.03 - Modeling Setup - Time Series Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from datetime import datetime\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('grayscale')\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from src.models.models import SetTempAsPower, SK_Prophet\n",
    "from src.utils.utils import bound_precision\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "PROJECT_DIR = pathlib.Path.cwd().parent.resolve()\n",
    "CLEAN_DATA_DIR = PROJECT_DIR / 'data' / '05-clean'\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp_max</th>\n",
       "      <th>dew_point_temp</th>\n",
       "      <th>week_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1994-01-01</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1994-01-02</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1994-01-03</td>\n",
       "      <td>-10.3</td>\n",
       "      <td>-12.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1994-01-04</td>\n",
       "      <td>-7.4</td>\n",
       "      <td>-11.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1994-01-05</td>\n",
       "      <td>-7.2</td>\n",
       "      <td>-10.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            temp_max  dew_point_temp  week_of_year\n",
       "1994-01-01       2.8             1.1          52.0\n",
       "1994-01-02       1.7             0.5          52.0\n",
       "1994-01-03     -10.3           -12.6           1.0\n",
       "1994-01-04      -7.4           -11.5           1.0\n",
       "1994-01-05      -7.2           -10.7           1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(CLEAN_DATA_DIR / 'clean-cut.csv', parse_dates=True, index_col=0)\n",
    "df = df.loc['1994': '2013']\n",
    "df = df.resample('D').max()\n",
    "# Just select a reasonable subset of data to test the model wrappers\n",
    "df = df[['temp', 'dew_point_temp', 'week_of_year', 'daily_peak']]\n",
    "df.rename(columns={'temp': 'temp_max'}, inplace=True)\n",
    "\n",
    "y = df.pop('daily_peak')\n",
    "X = df\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1994-01-01    16892.0\n",
       "1994-01-02    18947.0\n",
       "1994-01-03    21923.0\n",
       "1994-01-04    21457.0\n",
       "1994-01-05    22082.0\n",
       "Freq: D, Name: daily_peak, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013-12-27    18611.0\n",
       "2013-12-28    17651.0\n",
       "2013-12-29    17853.0\n",
       "2013-12-30    19997.0\n",
       "2013-12-31    19748.0\n",
       "Freq: D, Name: daily_peak, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Time Series Cross Validation\n",
    "\n",
    "### Scikit Learn Time Series Cross Validation\n",
    "Not Suitable because cannot select minimum train set size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train [datetime.date(1994, 1, 1)] [datetime.date(1995, 10, 27)]\n",
      "Validate [datetime.date(1995, 10, 28)] [datetime.date(1997, 8, 21)] \n",
      "\n",
      "Train [datetime.date(1994, 1, 1)] [datetime.date(1997, 8, 21)]\n",
      "Validate [datetime.date(1997, 8, 22)] [datetime.date(1999, 6, 16)] \n",
      "\n",
      "Train [datetime.date(1994, 1, 1)] [datetime.date(1999, 6, 16)]\n",
      "Validate [datetime.date(1999, 6, 17)] [datetime.date(2001, 4, 10)] \n",
      "\n",
      "Train [datetime.date(1994, 1, 1)] [datetime.date(2001, 4, 10)]\n",
      "Validate [datetime.date(2001, 4, 11)] [datetime.date(2003, 2, 3)] \n",
      "\n",
      "Train [datetime.date(1994, 1, 1)] [datetime.date(2003, 2, 3)]\n",
      "Validate [datetime.date(2003, 2, 4)] [datetime.date(2004, 11, 28)] \n",
      "\n",
      "Train [datetime.date(1994, 1, 1)] [datetime.date(2004, 11, 28)]\n",
      "Validate [datetime.date(2004, 11, 29)] [datetime.date(2006, 9, 23)] \n",
      "\n",
      "Train [datetime.date(1994, 1, 1)] [datetime.date(2006, 9, 23)]\n",
      "Validate [datetime.date(2006, 9, 24)] [datetime.date(2008, 7, 18)] \n",
      "\n",
      "Train [datetime.date(1994, 1, 1)] [datetime.date(2008, 7, 18)]\n",
      "Validate [datetime.date(2008, 7, 19)] [datetime.date(2010, 5, 13)] \n",
      "\n",
      "Train [datetime.date(1994, 1, 1)] [datetime.date(2010, 5, 13)]\n",
      "Validate [datetime.date(2010, 5, 14)] [datetime.date(2012, 3, 7)] \n",
      "\n",
      "Train [datetime.date(1994, 1, 1)] [datetime.date(2012, 3, 7)]\n",
      "Validate [datetime.date(2012, 3, 8)] [datetime.date(2013, 12, 31)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "for train_indx, val_indx in tscv.split(X):\n",
    "    print('Train', X.iloc[[train_indx[0]]].index.date,\n",
    "        X.iloc[[train_indx[-1]]].index.date)\n",
    "    print('Validate', X.iloc[[val_indx[0]]].index.date,\n",
    "        X.iloc[[val_indx[-1]]].index.date, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Cross Validation - Fixed Start\n",
    "\n",
    "\n",
    "We are looking for an annual splitting scheme that works like the following blue and green blocks\n",
    "\n",
    "Code up in cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Custom cross Validation](images/custom-cross-validation.PNG \"Custom Cross Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AnnualTimeSeriesSplit():\n",
    "    \"\"\"\n",
    "    Instantiate with number of folds\n",
    "    split accepts a pandas dataframe indexed by datetime covering multiple years sorted ascending\n",
    "    Splits to the number of folds, with a single year returned as the validation set\n",
    "    Walks up the timeseries yielding the indices from each train, test split\n",
    "    \"\"\"\n",
    "    def __init__(self, n_splits):\n",
    "        self.n_splits = n_splits\n",
    "        \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        years = X.index.year.unique()\n",
    "        \n",
    "        for ind, year in enumerate(years[0:self.n_splits]):\n",
    "            \n",
    "            final_train_year = years[-1] - self.n_splits + ind\n",
    "            \n",
    "            train_final_index = X.index.get_loc(str(final_train_year)).stop\n",
    "            test_final_index = X.index.get_loc(str(final_train_year + 1)).stop\n",
    "            \n",
    "            train_indices = list(range(0, train_final_index))\n",
    "            test_indices = list(range(train_final_index, test_final_index))\n",
    "            \n",
    "            yield train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train [datetime.date(1994, 1, 1)] [datetime.date(2003, 12, 31)]\n",
      "Validate [datetime.date(2004, 1, 1)] [datetime.date(2004, 12, 31)] \n",
      "\n",
      "Train [datetime.date(1994, 1, 1)] [datetime.date(2004, 12, 31)]\n",
      "Validate [datetime.date(2005, 1, 1)] [datetime.date(2005, 12, 31)] \n",
      "\n",
      "Train [datetime.date(1994, 1, 1)] [datetime.date(2005, 12, 31)]\n",
      "Validate [datetime.date(2006, 1, 1)] [datetime.date(2006, 12, 31)] \n",
      "\n",
      "Train [datetime.date(1994, 1, 1)] [datetime.date(2006, 12, 31)]\n",
      "Validate [datetime.date(2007, 1, 1)] [datetime.date(2007, 12, 31)] \n",
      "\n",
      "Train [datetime.date(1994, 1, 1)] [datetime.date(2007, 12, 31)]\n",
      "Validate [datetime.date(2008, 1, 1)] [datetime.date(2008, 12, 31)] \n",
      "\n",
      "Train [datetime.date(1994, 1, 1)] [datetime.date(2008, 12, 31)]\n",
      "Validate [datetime.date(2009, 1, 1)] [datetime.date(2009, 12, 31)] \n",
      "\n",
      "Train [datetime.date(1994, 1, 1)] [datetime.date(2009, 12, 31)]\n",
      "Validate [datetime.date(2010, 1, 1)] [datetime.date(2010, 12, 31)] \n",
      "\n",
      "Train [datetime.date(1994, 1, 1)] [datetime.date(2010, 12, 31)]\n",
      "Validate [datetime.date(2011, 1, 1)] [datetime.date(2011, 12, 31)] \n",
      "\n",
      "Train [datetime.date(1994, 1, 1)] [datetime.date(2011, 12, 31)]\n",
      "Validate [datetime.date(2012, 1, 1)] [datetime.date(2012, 12, 31)] \n",
      "\n",
      "Train [datetime.date(1994, 1, 1)] [datetime.date(2012, 12, 31)]\n",
      "Validate [datetime.date(2013, 1, 1)] [datetime.date(2013, 12, 31)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "atscv = AnnualTimeSeriesSplit(n_splits=10)\n",
    "\n",
    "for train_indx, val_indx in atscv.split(X):\n",
    "    print('Train', X.iloc[[train_indx[0]]].index.date,\n",
    "        X.iloc[[train_indx[-1]]].index.date)\n",
    "    print('Validate', X.iloc[[val_indx[0]]].index.date,\n",
    "        X.iloc[[val_indx[-1]]].index.date, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Time Series Cross Validation - Fixed Start\n",
    "\n",
    "\n",
    "We are looking for an annual splitting scheme that works like the following blue and green blocks\n",
    "\n",
    "Code up in cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![Custom cross Validation](images/rolling-cross-validation.PNG \"Custom Cross Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RollingAnnualTimeSeriesSplit():\n",
    "    \"\"\"\n",
    "    Instantiate with number of folds\n",
    "    split accepts a pandas dataframe indexed by datetime covering multiple years sorted ascending\n",
    "    Splits to the number of folds, with a single year returned as the validation set\n",
    "    Walks up the timeseries yielding the indices from each train, test split\n",
    "    \"\"\"\n",
    "    def __init__(self, n_splits, goback_years=5):\n",
    "        self.n_splits = n_splits\n",
    "        self.goback_years = goback_years\n",
    "        \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        years = X.index.year.unique()\n",
    "        \n",
    "        for ind, year in enumerate(years[0:self.n_splits]):\n",
    "            \n",
    "            final_train_year = years[-1] - self.n_splits + ind\n",
    "            start_train_year = final_train_year - self.goback_years +1\n",
    "            print(f'{final_train_year+1}')\n",
    "            \n",
    "            train_start_index = X.index.get_loc(str(start_train_year)).start\n",
    "            train_final_index = X.index.get_loc(str(final_train_year)).stop\n",
    "            test_final_index = X.index.get_loc(str(final_train_year + 1)).stop\n",
    "            \n",
    "            train_indices = list(range(train_start_index, train_final_index))\n",
    "            test_indices = list(range(train_final_index, test_final_index))\n",
    "            \n",
    "            yield train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ana_py37tf]",
   "language": "python",
   "name": "conda-env-ana_py37tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
